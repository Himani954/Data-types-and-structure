{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMys3zwP80T9yh0gMb555zA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Himani954/Data-types-and-structure/blob/main/Boosting_Techniques_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 1: What is Boosting in Machine Learning? Explain how it improves weak learners.**\n"
      ],
      "metadata": {
        "id": "fNF_SJWS_gIZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Answer1 :**\n",
        "# Boosting in Machine Learning\n",
        "Boosting is an ensemble learning technique in machine learning that combines multiple weak learners to create a strong predictive model. A weak learner is a model that performs slightly better than random guessing.\n",
        "\n",
        "How Boosting Improves Weak Learners\n",
        "1. Sequential Training : Boosting trains models sequentially. Each new model focuses on the mistakes made by the previous models.\n",
        "2. Weighted Combination : The predictions of these weak learners are combined, often through weighted voting, to produce a final prediction.\n",
        "3. Focus on Errors : By focusing on the errors or residuals of previous models, boosting improves the overall performance of the ensemble.\n",
        "\n",
        "Key Aspects of Boosting\n",
        "- Boosting reduces bias and can lead to improved accuracy by combining the predictions of multiple weak models.\n",
        "- Popular boosting algorithms include AdaBoost, Gradient Boosting, and XGBoost.\n",
        "- Boosting can handle complex data and is flexible with different base learners."
      ],
      "metadata": {
        "id": "uZUCGyAp_t8j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 2: What is the difference between AdaBoost and Gradient Boosting in terms of how models are trained?**\n"
      ],
      "metadata": {
        "id": "LNdgAO0GBdAm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Answer2 :**\n",
        "# Difference in Model Training\n",
        "AdaBoost and Gradient Boosting are boosting techniques in machine learning with distinct approaches to training models:\n",
        "\n",
        "1. AdaBoost (Adaptive Boosting) :\n",
        "    - In AdaBoost, the training data points are reweighted after each iteration. Misclassified points get higher weights so that the next model focuses more on these points.\n",
        "2. Gradient Boosting :\n",
        "    - Gradient Boosting trains models to fit the residuals (for regression) or pseudo-residuals (for classification or other loss functions) of the previous ensemble. It uses gradient descent to minimize the loss.\n",
        "\n",
        "Key Differences\n",
        "- Weight Adjustment vs. Residual Fitting : AdaBoost adjusts weights of data points for subsequent models. Gradient Boosting fits new models to the residuals or gradients of the loss.\n",
        "- Approach to Minimizing Loss : Gradient Boosting is more general in minimizing arbitrary loss functions via gradient descent."
      ],
      "metadata": {
        "id": "rcWPbJQoBq26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 3: How does regularization help in XGBoost?**"
      ],
      "metadata": {
        "id": "-x7ZvYVEDX8y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Answer3 :**\n",
        "Regularization in XGBoost\n",
        "XGBoost (Extreme Gradient Boosting) is an optimized implementation of gradient boosting that includes several features to prevent overfitting and improve model generalization. Regularization is a key aspect of how XGBoost helps in controlling model complexity and preventing overfitting.\n",
        "\n",
        "How Regularization Helps in XGBoost\n",
        "1. Control Model Complexity : XGBoost includes regularization terms in its objective function to penalize complex models. This helps in preventing overfitting by discouraging overly complex trees.\n",
        "2. Parameters for Regularization : XGBoost provides parameters like gamma, lambda, and alpha for regularization.\n",
        "    - gamma : Minimum loss reduction required to make a further partition on a leaf node. Higher values lead to more conservative models.\n",
        "    - lambda (L2 regularization) : Adds a penalty term for the sum of squares of weights.\n",
        "    - alpha (L1 regularization) : Adds a penalty on the sum of absolute values of weights.\n",
        "3. Preventing Overfitting : By tuning these regularization parameters, you can control the complexity of the model and improve its generalization ability on unseen data.\n"
      ],
      "metadata": {
        "id": "DomHYXm-EGMv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 4: Why is CatBoost considered efficient for handling categorical data?**"
      ],
      "metadata": {
        "id": "OvJzxZv5FkWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Answer 4:**\n",
        "# CatBoost and Categorical Data\n",
        "CatBoost is a gradient boosting library developed by Yandex that is considered efficient for handling categorical data.\n",
        "\n",
        "Why CatBoost is Efficient for Categorical Data\n",
        "1. Native Handling of Categorical Features : CatBoost can handle categorical features natively without needing one-hot encoding or other preprocessing techniques that might lead to high-dimensional data or loss of information.\n",
        "2. Ordered Boosting : CatBoost uses a technique called \"ordered boosting\" which helps in efficiently handling categorical features by considering the order of the categories in a way that reduces overfitting.\n",
        "3. Reducing Overfitting with Categorical Features : CatBoost implements strategies to handle categorical data in a way that reduces the risk of overfitting compared to traditional methods of encoding categorical variables.\n",
        "\n",
        "Advantages for Categorical Data\n",
        "- Ease of Use : CatBoost allows you to directly input categorical features without extensive preprocessing.\n",
        "- Performance : CatBoost's handling of categorical data can lead to good performance in terms of prediction accuracy."
      ],
      "metadata": {
        "id": "8hirBihrFwC2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 5: What are some real-world applications where boosting techniques are preferred over bagging methods?**"
      ],
      "metadata": {
        "id": "E1lpCfAvGp0G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Answer5 :**\n",
        "Boosting techniques are preferred over bagging methods in several real-world applications due to their ability to reduce bias and improve accuracy by sequentially correcting errors. Here are some areas where boosting shines:\n",
        "\n",
        "Applications Favoring Boosting\n",
        "- Ad Click Prediction : Boosting techniques like XGBoost are commonly used for tasks like ad click prediction due to their ability to handle complex patterns and improve accuracy.\n",
        "- Fraud Detection : Boosting algorithms like Gradient Boosting are highly effective in fraud detection because they sequentially improve on weak models, learning from previous mistakes to handle complex, imbalanced datasets.\n",
        "- Customer Segmentation and Classification Tasks : Boosting is particularly effective when you need to reduce bias and improve the accuracy of weak learners in tasks like customer segmentation.\n",
        "- Image Classification : Boosting can lead to higher accuracy than bagging when working with weak learners like shallow decision trees in complex tasks ¹ ².\n",
        "\n",
        "Why Choose Boosting?\n",
        "- Reducing Bias : Boosting focuses on reducing bias by sequentially correcting model errors.\n",
        "- Handling Complex Patterns : Boosting is effective on complex datasets where simple models might underperform.\n",
        "- Improving Accuracy : Boosting tends to produce better results for complex, hard-to-predict problems."
      ],
      "metadata": {
        "id": "Cz_3lr2aGzxi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 6: Write a Python program to:**\n",
        "# **● Train an AdaBoost Classifier on the Breast Cancer dataset**\n",
        "# **● Print the model accuracy**"
      ],
      "metadata": {
        "id": "kuG2hQjDJWmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize AdaBoost classifier\n",
        "model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xfn6TueYJl4m",
        "outputId": "60dd66d4-a6fd-4083-b29f-8634e75b684a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.9737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 7: Write a Python program to:**\n",
        "# **● Train a Gradient Boosting Regressor on the California Housing dataset**\n",
        "# **● Evaluate performance using R-squared score**"
      ],
      "metadata": {
        "id": "PYq1iqTjKBtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load California Housing dataset\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Gradient Boosting Regressor\n",
        "model = GradientBoostingRegressor(n_estimators=200, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate performance using R² score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"R² Score: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDB50Fm4Kkbz",
        "outputId": "2dfea22b-20bf-4787-f689-58dc57dc20ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² Score: 0.8004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 8: Write a Python program to:**\n",
        "# **● Train an XGBoost Classifier on the Breast Cancer dataset**\n",
        "# **● Tune the learning rate using GridSearchCV**\n",
        "# **● Print the best parameters and accuracy**"
      ],
      "metadata": {
        "id": "baw6y66uLC0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize XGBoost Classifier\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
        "\n",
        "# Define parameter grid for learning_rate\n",
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3]\n",
        "}\n",
        "\n",
        "# GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get best model\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "print(f\"Model Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTqkwritLROg",
        "outputId": "a54b9c70-e90c-4140-af4a-faf9edd1abc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'learning_rate': 0.2}\n",
            "Model Accuracy: 0.9561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [15:52:26] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 9: Write a Python program to:**\n",
        "# **● Train a CatBoost Classifier**\n",
        "# **● Plot the confusion matrix using seaborn**"
      ],
      "metadata": {
        "id": "TIpI2LUsLsme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# Create a small dataset (example)\n",
        "data = pd.DataFrame({\n",
        "    \"age\": [25, 32, 47, 51, 62, 23, 36, 44, 53, 61],\n",
        "    \"income\": [50000, 60000, 80000, 72000, 91000, 45000, 62000, 70000, 85000, 90000],\n",
        "    \"gender\": [\"M\", \"F\", \"M\", \"M\", \"F\", \"F\", \"M\", \"F\", \"M\", \"F\"],\n",
        "    \"region\": [\"North\", \"South\", \"East\", \"West\", \"East\", \"North\", \"South\", \"West\", \"East\", \"North\"],\n",
        "    \"default\": [0, 1, 0, 1, 0, 0, 1, 1, 1, 0]   # target variable\n",
        "})\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop(\"default\", axis=1)\n",
        "y = data[\"default\"]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Identify categorical features\n",
        "cat_features = [\"gender\", \"region\"]\n",
        "\n",
        "# Train CatBoost Classifier\n",
        "model = CatBoostClassifier(verbose=0)  # verbose=0 hides training logs\n",
        "model.fit(X_train, y_train, cat_features=cat_features)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"No Default\", \"Default\"], yticklabels=[\"No Default\", \"Default\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "MBvFOrWtICi4",
        "outputId": "78b552d9-8d24-4de3-a15d-9530d9941980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6666666666666666\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhcAAAG2CAYAAADMcaSeAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAN7pJREFUeJzt3Xt8FNX9//H3JCSbKBBuuQAGAnIXCDfFQCuFxqJYINhWaq0JoFipKBKpEH5CACtBFKQISkG5eQMKyBcNYmkqUiCKclFURMVgFJNwJwRwA7vz+8NHt90mQEJmMkn29fQxj0f37Jkzn02zDz75nHNmDNM0TQEAAFgkyOkAAABAzUJyAQAALEVyAQAALEVyAQAALEVyAQAALEVyAQAALEVyAQAALEVyAQAALEVyAQAALEVyAQAALEVyAQBADbVlyxYNHDhQTZo0kWEYWrdu3WXP2bx5s7p16yaXy6VWrVpp6dKl5b4uyQUAADXUmTNnFB8fr/nz55epf05Ojm677Tb17dtXe/bs0cMPP6x7771Xb7/9drmua/DgMgAAaj7DMPT6668rKSnpon3Gjx+vzMxMffLJJ7623/72tzp58qQ2btxY5mtRuQAAoJpwu90qLCz0O9xut2XjZ2dnKzEx0a+tf//+ys7OLtc4tSyLqAoJ7zra6RCAKunEB/OcDgGocsIq4V9Cq/5dGj+4kaZOnerXlp6erilTplgyfn5+vqKjo/3aoqOjVVhYqHPnzik8PLxM49TI5AIAgJooLS1Nqampfm0ul8uhaC6O5AIAALsZ1qxCcLlctiYTMTExKigo8GsrKChQ3bp1y1y1kEguAACwn2E4HUGZJCQkaMOGDX5tmzZtUkJCQrnGYUEnAAB2M4KsOcqpqKhIe/bs0Z49eyT9uNV0z549ys3NlfTjNEtycrKv//3336+vv/5ajz76qD7//HM999xzWrVqlcaOHVuu65JcAABQQ3344Yfq2rWrunbtKklKTU1V165dNXnyZElSXl6eL9GQpBYtWigzM1ObNm1SfHy8Zs2apRdeeEH9+/cv13Vr5H0u2C0ClI7dIkBJlbJb5PrUy3cqg3MfzLZkHLux5gIAALtZtKCzugisTwsAAGxH5QIAALtVk90iViG5AADAbkyLAAAAXDkqFwAA2I1pEQAAYCmmRQAAAK4clQsAAOzGtAgAALBUgE2LkFwAAGC3AKtcBFYqBQAAbEflAgAAuzEtAgAALBVgyUVgfVoAAGA7KhcAANgtKLAWdJJcAABgN6ZFAAAArhyVCwAA7BZg97kguQAAwG5MiwAAAFw5KhcAANiNaREAAGCpAJsWIbkAAMBuAVa5CKxUCgAA2I7KBQAAdmNaBAAAWIppEQAAgCtH5QIAALsxLQIAACzFtAgAAMCVo3IBAIDdmBYBAACWCrDkIrA+LQAAsB2VCwAA7BZgCzpJLgAAsFuATYuQXAAAYLcAq1wEVioFAABsR+UCAAC7MS0CAAAsxbQIAADAlaNyAQCAzYwAq1yQXAAAYLNASy6YFgEAAJaicgEAgN0Cq3BBcgEAgN2YFgEAAKgAKhcAANgs0CoXJBcAANiM5AIAAFgq0JILx9dctGzZUseOHSvRfvLkSbVs2dKBiAAAQEU4Xrk4ePCgPB5PiXa3261Dhw45EBEAABYLrMKFc8nF+vXrff/77bffVkREhO+1x+NRVlaW4uLiHIgMAABrBdq0iGPJRVJSkqQff+ApKSl+74WEhCguLk6zZs1yIDIAAFARjiUXXq9XktSiRQt98MEHatSokVOhAABgKyoXlSwnJ8fpEAAAsBXJRSWYO3dumfs+9NBDNkYCAACs5khy8cwzz5Spn2EYJBcAgGqPykUlYCoEABBQAiu3cP4mWgAAoGZxfEHniBEjLvn+4sWLKykSAADswbRIJTtx4oTf6/Pnz+uTTz7RyZMn1a9fP4eiAgDAOiQXlez1118v0eb1ejVq1Chde+21DkQEAIC1Ai25qJJrLoKCgpSamlrmXSUAAKB08+fPV1xcnMLCwtSzZ0/t2LHjkv3nzJmjtm3bKjw8XLGxsRo7dqx++OGHcl2zSiYXknTgwAFduHDB6TAAAKg4w6KjnFauXKnU1FSlp6dr165dio+PV//+/XX48OFS+7/66quaMGGC0tPTtW/fPr344otauXKlJk6cWK7rOj4tkpqa6vfaNE3l5eUpMzOzxDNHAACojpyaFpk9e7ZGjhyp4cOHS5IWLFigzMxMLV68WBMmTCjRf/v27erdu7d+97vfSZLi4uJ055136v333y/XdR1PLnbv3u33OigoSJGRkZo1a9Zld5IAABBI3G633G63X5vL5ZLL5SrRt7i4WDt37lRaWpqvLSgoSImJicrOzi51/F69eunll1/Wjh07dMMNN+jrr7/Whg0bdPfdd5crTseTi3feecfpEAAAsJVVlYuMjAxNnTrVry09PV1Tpkwp0ffo0aPyeDyKjo72a4+Ojtbnn39e6vi/+93vdPToUf3kJz+RaZq6cOGC7r///nJPi1TZNRcAANQUhmFYcqSlpenUqVN+x39XJipq8+bNmj59up577jnt2rVLa9euVWZmph5//PFyjeN45UKSVq9erVWrVik3N1fFxcV+7+3atcuhqAAAqFouNgVSmkaNGik4OFgFBQV+7QUFBYqJiSn1nEmTJunuu+/WvffeK0nq1KmTzpw5o/vuu0//7//9PwUFla0m4XjlYu7cuRo+fLiio6O1e/du3XDDDWrYsKG+/vpr3XrrrU6HBwBAhVlVuSiP0NBQde/eXVlZWb42r9errKwsJSQklHrO2bNnSyQQwcHBkn7ccFFWjicXzz33nBYuXKhnn31WoaGhevTRR7Vp0yY99NBDOnXqlNPhAQBQcQ5tRU1NTdWiRYu0bNky7du3T6NGjdKZM2d8u0eSk5P9plUGDhyo559/XitWrFBOTo42bdqkSZMmaeDAgb4koywcnxbJzc1Vr169JEnh4eE6ffq0JOnuu+/WjTfeqHnz5jkZHgAA1dbQoUN15MgRTZ48Wfn5+erSpYs2btzoW+SZm5vrV6l47LHHZBiGHnvsMR06dEiRkZEaOHCgnnjiiXJd1/HkIiYmRsePH1fz5s3VrFkzvffee4qPj1dOTk65SjAAAFRVTt7+e/To0Ro9enSp723evNnvda1atZSenq709PQKXdPxaZF+/fpp/fr1kqThw4dr7NixuvnmmzV06FANGTLE4egAAKg4J9ZcOMnxysXChQvl9XolSQ888IAaNmyo7du3a9CgQfrDH/7gcHQAAFRcdUoMrOBI5eL2229XYWGhJOnll1+Wx+Pxvffb3/5Wc+fO1YMPPqjQ0FAnwgMAABXgSHLx5ptv6syZM5J+nAphVwgAoEZzaLeIUxyZFmnXrp3S0tLUt29fmaapVatWqW7duqX2TU5OruToAACwVqBNiziSXCxYsECpqanKzMz0bXkp7QdvGAbJBQAA1YwjyUWvXr303nvvSfrxCW1ffPGFoqKinAgFNund7VqNTU5Utw7N1DgyQneMXag3Nn/sdFiA41a8+oqWLXlRR48eUZu27TRh4iR16tzZ6bBgs0CrXDi+FTUnJ0eRkZFOhwGLXR3u0t4vDunhjJVOhwJUGRvf2qCnZ2boD398QCv+9rratm2nUX+4R8eOHXM6NNgs0LaiOp5cNG/eXFu3btXvf/97JSQk6NChQ5Kkl156SVu3bnU4Olypv2/7TFOfe1Pr36FaAfzbS8uW6PZf36GkIb/Sta1a6bH0qQoLC9O6tWucDg2wlOPJxZo1a9S/f3+Fh4dr9+7dcrvdkqRTp05p+vTpDkcHANY4X1ysfZ99qhsTevnagoKCdOONvfTxR7sdjAyVgcpFJfvzn/+sBQsWaNGiRQoJCfG19+7dm8etA6gxTpw8IY/Ho4YNG/q1N2zYUEePHnUoKlQatqJWrv379+umm24q0R4REaGTJ09e9ny32+2rdvyb6fXICCr709sAAIB1HK9cxMTE6KuvvirRvnXrVrVs2fKy52dkZCgiIsLvuFCw045QAeCK1a9XX8HBwSUWbx47dkyNGjVyKCpUFqZFKtnIkSM1ZswYvf/++zIMQ99//71eeeUVjRs3TqNGjbrs+WlpaTp16pTfUSu6eyVEDgBlFxIaqvYdrtP772X72rxer95/P1ud47s6GBkqQ6AlF45Pi0yYMEFer1c///nPdfbsWd10001yuVwaN26cHnzwwcue73K55HK5/NqYEnHe1eGhujb2P1uM45o2VOc2TXWi8Ky+zT/hYGSAc+5OGa5JE8fruus6qmOnznr5pWU6d+6ckobc7nRosFk1ygssYZimaTodhCQVFxfrq6++UlFRkTp06KDatWtf8VjhXUt/bj0qz0+7t9bfXxhTov2l9e/pvvSXHYgIknTig3lOhxDwXnvlZd9NtNq2a6/xEx9T587xTocV0MIq4c/sVuPesmScr56+1ZJx7FYlkgvTNHXs2DEZhlFiJfWVILkASkdyAZRUGclF6z9ttGScL5+6xZJx7Obomov8/HwlJyerfv36io6OVlRUlOrXr68RI0aooKDAydAAALCMYVhzVBeOrbkoLCxUr169VFRUpOHDh6tdu3YyTVOfffaZXnvtNW3dulW7du2q0PQIAACofI4lF3/5y18UHBysTz/9tMSzRR577DH17t1bc+fO1cSJEx2KEAAAa1SnnR5WcGxaJDMzUxMnTiz1oWVRUVFKS0vTG2+84UBkAABYK9CmRRxLLr744gv16tXrou/36tVL+/fvr8SIAACAFRxdc1GvXr2Lvl+vXj0VFhZWXkAAANgkKKgalR0s4FhyYZqmgoIuXjgxDENVYJcsAAAVVp2mNKzgaHLRpk2biy5yIbEAAKB6ciy5WLJkiVOXBgCgUgXabhHHkouUlBSnLg0AQKUKsNzC+QeXAQBQ0wVa5cLxR64DAICahcoFAAA2C7TKBckFAAA2C7DcompNi5imyRZUAACquSqRXCxfvlydOnVSeHi4wsPD1blzZ7300ktOhwUAgCUMw7DkqC4cnxaZPXu2Jk2apNGjR6t3796SpK1bt+r+++/X0aNHNXbsWIcjBACgYqpRXmAJx5OLZ599Vs8//7ySk5N9bYMGDdJ1112nKVOmkFwAAFDNOJ5c5OXllfp01F69eikvL8+BiAAAsFZ1mtKwguNrLlq1aqVVq1aVaF+5cqVat27tQEQAAFjLMKw5qgvHKxdTp07V0KFDtWXLFt+ai23btikrK6vUpAMAAFRtjicXv/rVr/T+++/rmWee0bp16yRJ7du3144dO9S1a1dngwMAwAKBNi3ieHIhSd27d9fLL7/sdBgAANgiwHKLqpFcAABQk1G5qCRBQUGX/WEbhqELFy5UUkQAAMAKjiUXr7/++kXfy87O1ty5c+X1eisxIgAA7BFghQvnkovBgweXaNu/f78mTJigN954Q3fddZemTZvmQGQAAFgr0KZFHL/PhSR9//33GjlypDp16qQLFy5oz549WrZsmZo3b+50aAAAoJwcTS5OnTql8ePHq1WrVvr000+VlZWlN954Qx07dnQyLAAALMVNtCrJzJkz9eSTTyomJkavvfZaqdMkAADUBIE2LeJYcjFhwgSFh4erVatWWrZsmZYtW1Zqv7Vr11ZyZAAAoCIcSy6Sk5MDLpMDAASmQPvnzrHkYunSpU5dGgCAShVof0xXid0iAACg5uD23wAA2CzQKhckFwAA2CzAcguSCwAA7BZolQvWXAAAAEtRuQAAwGYBVrgguQAAwG5MiwAAAFQAlQsAAGwWYIULkgsAAOwWFGDZBdMiAADAUlQuAACwWYAVLkguAACwG7tFAACApYIMa44rMX/+fMXFxSksLEw9e/bUjh07Ltn/5MmTeuCBB9S4cWO5XC61adNGGzZsKNc1qVwAAFBDrVy5UqmpqVqwYIF69uypOXPmqH///tq/f7+ioqJK9C8uLtbNN9+sqKgorV69Wk2bNtU333yjevXqleu6JBcAANjMqWmR2bNna+TIkRo+fLgkacGCBcrMzNTixYs1YcKEEv0XL16s48ePa/v27QoJCZEkxcXFlfu6TIsAAGAzw7DmcLvdKiws9Dvcbnep1ywuLtbOnTuVmJjoawsKClJiYqKys7NLPWf9+vVKSEjQAw88oOjoaHXs2FHTp0+Xx+Mp1+cluQAAoJrIyMhQRESE35GRkVFq36NHj8rj8Sg6OtqvPTo6Wvn5+aWe8/XXX2v16tXyeDzasGGDJk2apFmzZunPf/5zueJkWgQAAJsZsmZaJC0tTampqX5tLpfLkrElyev1KioqSgsXLlRwcLC6d++uQ4cO6amnnlJ6enqZxyG5AADAZle60+N/uVyuMicTjRo1UnBwsAoKCvzaCwoKFBMTU+o5jRs3VkhIiIKDg31t7du3V35+voqLixUaGlqmazMtAgBADRQaGqru3bsrKyvL1+b1epWVlaWEhIRSz+ndu7e++uoreb1eX9sXX3yhxo0blzmxkEguAACwnWEYlhzllZqaqkWLFmnZsmXat2+fRo0apTNnzvh2jyQnJystLc3Xf9SoUTp+/LjGjBmjL774QpmZmZo+fboeeOCBcl2XaREAAGzm1A06hw4dqiNHjmjy5MnKz89Xly5dtHHjRt8iz9zcXAUF/afOEBsbq7fffltjx45V586d1bRpU40ZM0bjx48v13UN0zRNSz9JFRDedbTTIQBV0okP5jkdAlDlhFXCn9lJL3xoyTjr7u1hyTh2o3IBAIDNAu2R6yQXAADYLMByC5ILAADsxlNRAQAAKoDKBQAANguwwgXJBQAAdgu0BZ1MiwAAAEtRuQAAwGaBVbcguQAAwHbsFgEAAKgAKhcAANjMqkeuVxdlSi7Wr19f5gEHDRp0xcEAAFATBdq0SJmSi6SkpDINZhiGPB5PReIBAADVXJmSC6/Xa3ccAADUWAFWuGDNBQAAdmNapAzOnDmjd999V7m5uSouLvZ776GHHrIkMAAAagoWdF7G7t27NWDAAJ09e1ZnzpxRgwYNdPToUV111VWKiooiuQAAIMCV+z4XY8eO1cCBA3XixAmFh4frvffe0zfffKPu3bvr6aeftiNGAACqNcMwLDmqi3InF3v27NEjjzyioKAgBQcHy+12KzY2VjNnztTEiRPtiBEAgGrNsOioLsqdXISEhCgo6MfToqKilJubK0mKiIjQt99+a210AACg2in3mouuXbvqgw8+UOvWrdWnTx9NnjxZR48e1UsvvaSOHTvaESMAANUaj1y/jOnTp6tx48aSpCeeeEL169fXqFGjdOTIES1cuNDyAAEAqO4Mw5qjuih35aJHjx6+/x0VFaWNGzdaGhAAAKjeuIkWAAA2q047PaxQ7uSiRYsWl/whff311xUKCACAmibAcovyJxcPP/yw3+vz589r9+7d2rhxo/70pz9ZFRcAAKimyp1cjBkzptT2+fPn68MPP6xwQAAA1DTsFrlCt956q9asWWPVcAAA1BjsFrlCq1evVoMGDawaDgCAGoMFnZfRtWtXvx+SaZrKz8/XkSNH9Nxzz1kaHAAAqH7KnVwMHjzYL7kICgpSZGSkfvazn6ldu3aWBgfAWvWvH+10CECVc273PNuvYdkahGqi3MnFlClTbAgDAICaK9CmRcqdTAUHB+vw4cMl2o8dO6bg4GBLggIAANVXuSsXpmmW2u52uxUaGlrhgAAAqGmCAqtwUfbkYu7cuZJ+LO288MILql27tu89j8ejLVu2sOYCAIBSkFxcxDPPPCPpx8rFggUL/KZAQkNDFRcXpwULFlgfIQAAqFbKnFzk5ORIkvr27au1a9eqfv36tgUFAEBNEmgLOsu95uKdd96xIw4AAGqsQJsWKfdukV/96ld68sknS7TPnDlTv/nNbywJCgAAVF/lTi62bNmiAQMGlGi/9dZbtWXLFkuCAgCgJuHZIpdRVFRU6pbTkJAQFRYWWhIUAAA1CU9FvYxOnTpp5cqVJdpXrFihDh06WBIUAAA1SZBFR3VR7srFpEmTdPvtt+vAgQPq16+fJCkrK0uvvvqqVq9ebXmAAACgeil3cjFw4ECtW7dO06dP1+rVqxUeHq74+Hj985//5JHrAACUIsBmRcqfXEjSbbfdpttuu02SVFhYqNdee03jxo3Tzp075fF4LA0QAIDqjjUXZbRlyxalpKSoSZMmmjVrlvr166f33nvPytgAAEA1VK7KRX5+vpYuXaoXX3xRhYWFuuOOO+R2u7Vu3ToWcwIAcBEBVrgoe+Vi4MCBatu2rT7++GPNmTNH33//vZ599lk7YwMAoEYIMqw5qosyVy7eeustPfTQQxo1apRat25tZ0wAAKAaK3PlYuvWrTp9+rS6d++unj17at68eTp69KidsQEAUCMEGYYlR3VR5uTixhtv1KJFi5SXl6c//OEPWrFihZo0aSKv16tNmzbp9OnTdsYJAEC1FWi3/y73bpGrr75aI0aM0NatW7V371498sgjmjFjhqKiojRo0CA7YgQAANVIhe4m2rZtW82cOVPfffedXnvtNatiAgCgRmFB5xUIDg5WUlKSkpKSrBgOAIAaxVA1ygwsYElyAQAALq46VR2sUJ0esgYAAKoBKhcAANgs0CoXJBcAANjMqE77SC3AtAgAALAUlQsAAGzGtAgAALBUgM2KMC0CAACsReUCAACbVaeHjlmBygUAADZz8vbf8+fPV1xcnMLCwtSzZ0/t2LGjTOetWLFChmFc0d23SS4AAKihVq5cqdTUVKWnp2vXrl2Kj49X//79dfjw4Uued/DgQY0bN04//elPr+i6JBcAANjMqUeuz549WyNHjtTw4cPVoUMHLViwQFdddZUWL1580XM8Ho/uuusuTZ06VS1btryiz0tyAQCAzYJkWHK43W4VFhb6HW63u9RrFhcXa+fOnUpMTPxPHEFBSkxMVHZ29kVjnTZtmqKionTPPfdU4PMCAABbWVW5yMjIUEREhN+RkZFR6jWPHj0qj8ej6Ohov/bo6Gjl5+eXes7WrVv14osvatGiRRX6vOwWAQCgmkhLS1Nqaqpfm8vlsmTs06dP6+6779aiRYvUqFGjCo1FcgEAgM2sukOny+UqczLRqFEjBQcHq6CgwK+9oKBAMTExJfofOHBABw8e1MCBA31tXq9XklSrVi3t379f1157bZmuzbQIAAA2CzIMS47yCA0NVffu3ZWVleVr83q9ysrKUkJCQon+7dq10969e7Vnzx7fMWjQIPXt21d79uxRbGxsma9N5QIAgBoqNTVVKSkp6tGjh2644QbNmTNHZ86c0fDhwyVJycnJatq0qTIyMhQWFqaOHTv6nV+vXj1JKtF+OSQXAADYzKkbdA4dOlRHjhzR5MmTlZ+fry5dumjjxo2+RZ65ubkKCrJ+EsMwTdO0fFSHhXcd7XQIAIBq4tzuebZf48UduZaMc88NzSwZx26suQAAAJZiWgQAAJsF2HPLSC4AALBboE0TBNrnBQAANqNyAQCAzYwAmxchuQAAwGaBlVqQXAAAYLvy3l2zumPNBQAAsBSVCwAAbBZYdQuSCwAAbBdgsyJMiwAAAGtRuQAAwGZsRQUAAJYKtGmCQPu8AADAZlQuAACwGdMiAADAUoGVWjAtAgAALEblAgAAmzEtAgAALBVo0wQkFwAA2CzQKheBlkwBAACbUbkAAMBmgVW3ILkAAMB2ATYrwrQIAACwFpULAABsFhRgEyMkFwAA2IxpEQeMGDFCp0+fLtF+5swZjRgxwoGIAADAlaoSycWyZct07ty5Eu3nzp3T8uXLHYgIAADrGBb9V104Oi1SWFgo0zRlmqZOnz6tsLAw33sej0cbNmxQVFSUgxECAFBxgTYt4mhyUa9ePRmGIcMw1KZNmxLvG4ahqVOnOhAZAAC4Uo4mF++8845M01S/fv20Zs0aNWjQwPdeaGiomjdvriZNmjgYIQAAFcdukUrUp08fSVJOTo6aNWsWcPdeBwAEhkD7582x5OLjjz/2e713796L9u3cubPd4QAAYBuSi0rSpUsXGYYh0zQv2c8wDHk8nkqKCgAAVJRjyUVOTo5TlwYAoFJVp22kVnAsuWjevLlTlwYAoFIFBVZuUTVu/325G2UlJydXUiQAAKCiqkRyMWbMGL/X58+f19mzZxUaGqqrrrqK5AIAUK0xLeKAEydOlGj78ssvNWrUKP3pT39yICIAAKwTaLtFqsSzRUrTunVrzZgxo0RVAwAAVG1VonJxMbVq1dL333/vdBgAAFQI0yIOWL9+vd9r0zSVl5enefPmqXfv3g5FBQCANdgt4oCkpCS/14ZhKDIyUv369dOsWbOcCQoAAFyRKpFceL1ep0OAxXp3u1ZjkxPVrUMzNY6M0B1jF+qNzR9f/kSgBuN7EbgCbVqkyi7oRPV2dbhLe784pIczVjodClBl8L0IXIZhzVFdVInKhSR99913Wr9+vXJzc1VcXOz33uzZsx2KClfq79s+09+3feZ0GECVwvcicFWjvMASVSK5yMrK0qBBg9SyZUt9/vnn6tixow4ePCjTNNWtWzenwwMAAOVQJaZF0tLSNG7cOO3du1dhYWFas2aNvv32W/Xp00e/+c1vLnmu2+1WYWGh32F6eYoqAKDqCDIMS47qokokF/v27fPd4rtWrVo6d+6cateurWnTpunJJ5+85LkZGRmKiIjwOy4U7KyMsAEAKBPDoqO6qBLJxdVXX+1bZ9G4cWMdOHDA997Ro0cveW5aWppOnTrld9SK7m5rvAAA4OKqxJqLG2+8UVu3blX79u01YMAAPfLII9q7d6/Wrl2rG2+88ZLnulwuuVwuvzYjKNjOcAEAKJ/qVHawQJVILmbPnq2ioiJJ0tSpU1VUVKSVK1eqdevW7BSppq4OD9W1sZG+13FNG6pzm6Y6UXhW3+aXfFAdEAj4XgSuQLvPhWGapunEhefOnav77rtPYWFhys3NVWxsrAyLFquEdx1tyTi4cj/t3lp/f6HkQ+deWv+e7kt/2YGIAOfxvaiazu2eZ/s13j9wypJxel4bYck4dnMsufj3Q8mioqIUHBysvLw8RUVFWTI2yQUAoKwqI7nY8bU1ycUNLatHcuHYtEiTJk20Zs0aDRgwQKZp6rvvvtMPP/xQat9mzZpVcnQAAFgnsCZFHKxcLFy4UA8++KAuXLhw0T6macowDHk85btvBZULAEBZVUbl4gOLKhfXU7m4tPvuu0933nmnvvnmG3Xu3Fn/+Mc/1LBhQ6fCAQDAPgFWunB0t0idOnXUsWNHLVmyRL179y6xpRQAgJog0HaLVImbaKWkpOjcuXN64YUXlJaWpuPHj0uSdu3apUOHDjkcHQAAFcNTUR3w8ccfKzExURERETp48KBGjhypBg0aaO3atcrNzdXy5cudDhEAAJRRlahcjB07VsOGDdOXX36psLAwX/uAAQO0ZcsWByMDAKDiAu3ZIlWicvHhhx9q4cKFJdqbNm2q/Px8ByICAMBC1SkzsECVqFy4XC4VFhaWaP/iiy8UGRlZyhkAAKCqqhLJxaBBgzRt2jSdP39ekmQYhnJzczV+/Hj96le/cjg6AAAqxrDovysxf/58xcXFKSwsTD179tSOHTsu2nfRokX66U9/qvr166t+/fpKTEy8ZP+LqRLJxaxZs1RUVKTIyEidO3dOffr0UatWrVSnTh098cQTTocHAECFOLVbZOXKlUpNTVV6erp27dql+Ph49e/fX4cPHy61/+bNm3XnnXfqnXfeUXZ2tmJjY/WLX/yi3Ds3HbtDZ2m2bdumjz76SEVFRerWrZsSExOvaBzu0AkAKKvKuEPnntzTlozTpVmdcvXv2bOnrr/+es2b9+Nn9Hq9io2N1YMPPqgJEyZc9nyPx6P69etr3rx5Sk5OLvN1HV/Q6fV6tXTpUq1du1YHDx6UYRhq0aKFYmJifLf/BgCgOrPqXzK32y232+3X5nK5Sr0JZXFxsXbu3Km0tDRfW1BQkBITE5WdnV2m6509e1bnz59XgwYNyhWno9Mipmlq0KBBuvfee3Xo0CF16tRJ1113nb755hsNGzZMQ4YMcTI8AACsYdFe1IyMDEVERPgdGRkZpV7y6NGj8ng8io6O9muPjo4u807M8ePHq0mTJuWeSXC0crF06VJt2bJFWVlZ6tu3r997//znP5WUlKTly5eXqxQDAEBNlZaWptTUVL82ux6dMWPGDK1YsUKbN2/2uwdVWThauXjttdc0ceLEEomFJPXr108TJkzQK6+84kBkAABYx6rdIi6XS3Xr1vU7LpZcNGrUSMHBwSooKPBrLygoUExMzCXjffrppzVjxgz9/e9/V+fOncv9eR1NLj7++GPdcsstF33/1ltv1UcffVSJEQEAYD0ndouEhoaqe/fuysrK8rV5vV5lZWUpISHhoufNnDlTjz/+uDZu3KgePXpc0ed1dFrk+PHjJeaC/lt0dLROnDhRiREBAGA9p7YmpKamKiUlRT169NANN9ygOXPm6MyZMxo+fLgkKTk5WU2bNvWt23jyySc1efJkvfrqq4qLi/Otzahdu7Zq165d5us6mlx4PB7VqnXxEIKDg3XhwoVKjAgAgJpj6NChOnLkiCZPnqz8/Hx16dJFGzdu9P1hn5ubq6Cg/0xiPP/88youLtavf/1rv3HS09M1ZcqUMl/X0ftcBAUF6dZbb73ofJHb7dbGjRvl8XjKNS73uQAAlFVl3Ofik0NFlozTsWnZqwdOcrRykZKSctk+7BQBAFR3V3rr7urK0eRiyZIlTl4eAADYwPE7dAIAUNMF2s2mSS4AALBZgOUWVeOpqAAAoOagcgEAgN0CrHRBcgEAgM0CbbcI0yIAAMBSVC4AALAZu0UAAIClAiy3ILkAAMB2AZZdsOYCAABYisoFAAA2C7TdIiQXAADYLNAWdDItAgAALEXlAgAAmwVY4YLkAgAA2wVYdsG0CAAAsBSVCwAAbMZuEQAAYCl2iwAAAFQAlQsAAGwWYIULkgsAAGwXYNkFyQUAADYLtAWdrLkAAACWonIBAIDNAm23CMkFAAA2C7DcgmkRAABgLSoXAADYjGkRAABgscDKLpgWAQAAlqJyAQCAzZgWAQAAlgqw3IJpEQAAYC0qFwAA2IxpEQAAYKlAe7YIyQUAAHYLrNyCNRcAAMBaVC4AALBZgBUuSC4AALBboC3oZFoEAABYisoFAAA2Y7cIAACwVmDlFkyLAAAAa1G5AADAZgFWuCC5AADAbuwWAQAAqAAqFwAA2IzdIgAAwFJMiwAAAFQAyQUAALAU0yIAANgs0KZFSC4AALBZoC3oZFoEAABYisoFAAA2Y1oEAABYKsByC6ZFAACAtahcAABgtwArXZBcAABgM3aLAAAAVACVCwAAbMZuEQAAYKkAyy1ILgAAsF2AZResuQAAoAabP3++4uLiFBYWpp49e2rHjh2X7P+3v/1N7dq1U1hYmDp16qQNGzaU+5okFwAA2Myw6L/yWrlypVJTU5Wenq5du3YpPj5e/fv31+HDh0vtv337dt1555265557tHv3biUlJSkpKUmffPJJ+T6vaZpmuaOt4sK7jnY6BABANXFu9zzbr/HDBWvGCSvnYoaePXvq+uuv17x5P35Gr9er2NhYPfjgg5owYUKJ/kOHDtWZM2f05ptv+tpuvPFGdenSRQsWLCjzdalcAABQTbjdbhUWFvodbre71L7FxcXauXOnEhMTfW1BQUFKTExUdnZ2qedkZ2f79Zek/v37X7T/xdTIBZ2VkYXi8txutzIyMpSWliaXy+V0OECVwXcj8JS34nAxU/6coalTp/q1paena8qUKSX6Hj16VB6PR9HR0X7t0dHR+vzzz0sdPz8/v9T++fn55YqTygVs43a7NXXq1Itm1UCg4ruBK5WWlqZTp075HWlpaU6HVUKNrFwAAFATuVyuMle7GjVqpODgYBUUFPi1FxQUKCYmptRzYmJiytX/YqhcAABQA4WGhqp79+7KysrytXm9XmVlZSkhIaHUcxISEvz6S9KmTZsu2v9iqFwAAFBDpaamKiUlRT169NANN9ygOXPm6MyZMxo+fLgkKTk5WU2bNlVGRoYkacyYMerTp49mzZql2267TStWrNCHH36ohQsXluu6JBewjcvlUnp6OgvWgP/BdwOVZejQoTpy5IgmT56s/Px8denSRRs3bvQt2szNzVVQ0H8mMXr16qVXX31Vjz32mCZOnKjWrVtr3bp16tixY7muWyPvcwEAAJzDmgsAAGApkgsAAGApkgsAAGApkgs4Ztu2berUqZNCQkKUlJRk2bhxcXGaM2eOZeMBFbVw4ULFxsYqKCjIst/NgwcPyjAM7dmzx5LxACuRXNQww4YNk2EYmjFjhl/7unXrZBjlf6Lef1u6dKkMw5BhGAoODlb9+vXVs2dPTZs2TadOnSr3eKmpqerSpYtycnK0dOnSCsV2KYZhaN26dbaNj5rp398lwzAUEhKi6Oho3XzzzVq8eLG8Xm+ZxyksLNTo0aM1fvx4HTp0SPfdd58t8W7evFmGYejkyZO2jA+UB8lFDRQWFqYnn3xSJ06csHzsunXrKi8vT9999522b9+u++67T8uXL1eXLl30/fffl2usAwcOqF+/frrmmmtUr149y2MFKuqWW25RXl6eDh48qLfeekt9+/bVmDFj9Mtf/lIXLpTtMZe5ubk6f/68brvtNjVu3FhXXXWVzVEDziO5qIESExMVExPjuynKxaxZs0bXXXedXC6X4uLiNGvWrMuObRiGYmJi1LhxY7Vv31733HOPtm/frqKiIj366KO+fl6vVxkZGWrRooXCw8MVHx+v1atXS/pPOffYsWMaMWKEDMPQ0qVL5fF4dM899/jOadu2rf7yl7/4Xf9nP/uZHn74Yb+2pKQkDRs2rNR44+LiJElDhgyRYRi+10BZuFwuxcTEqGnTpurWrZsmTpyo//u//9Nbb73lq7adPHlS9957ryIjI1W3bl3169dPH330kaQfq32dOnWSJLVs2VKGYejgwYM6cOCABg8erOjoaNWuXVvXX3+9/vGPf/hdu7SKW7169Uqt8h08eFB9+/aVJNWvX1+GYVz0OwFUBpKLGig4OFjTp0/Xs88+q++++67UPjt37tQdd9yh3/72t9q7d6+mTJmiSZMmXdH0RFRUlO666y6tX79eHo9HkpSRkaHly5drwYIF+vTTTzV27Fj9/ve/17vvvqvY2Fjl5eWpbt26mjNnjvLy8jR06FB5vV5dc801+tvf/qbPPvtMkydP1sSJE7Vq1aor/ll88MEHkqQlS5YoLy/P9xq4Uv369VN8fLzWrl0rSfrNb36jw4cP66233tLOnTvVrVs3/fznP9fx48c1dOhQX9KwY8cO5eXlKTY2VkVFRRowYICysrK0e/du3XLLLRo4cKByc3OvKKbY2FitWbNGkrR//37l5eWVSMyBysQdOmuoIUOGqEuXLkpPT9eLL75Y4v3Zs2fr5z//uSZNmiRJatOmjT777DM99dRTV/QXT7t27XT69GkdO3ZMERERmj59uv7xj3/47kffsmVLbd26VX/961/Vp08fxcTEyDAMRURE+D0Q578fJdyiRQtlZ2dr1apVuuOOO8odkyRFRkZK+vEvvvI+eAe4mHbt2unjjz/W1q1btWPHDh0+fNh3t82nn35a69at0+rVq3XfffepYcOGkn78Xfz372B8fLzi4+N94z3++ON6/fXXtX79eo0ePbrc8QQHB6tBgwaSfkz2mWaE00guarAnn3xS/fr107hx40q8t2/fPg0ePNivrXfv3pozZ448Ho+Cg4PLda1/3+jVMAx99dVXOnv2rG6++Wa/PsXFxerateslx5k/f74WL16s3NxcnTt3TsXFxerSpUu5YgHsZpqmDMPQRx99pKKiIl8C8W/nzp3TgQMHLnp+UVGRpkyZoszMTOXl5enChQs6d+7cFVcugKqG5KIGu+mmm9S/f3+lpaXZPv+6b98+1a1bVw0bNtTXX38tScrMzFTTpk39+l3qWQorVqzQuHHjNGvWLCUkJKhOnTp66qmn9P777/v6BAUF6X/vWH/+/HkLPwlwefv27VOLFi1UVFSkxo0ba/PmzSX6XKp6MG7cOG3atElPP/20WrVqpfDwcP36179WcXGxr49hGPyuo9oiuajhZsyYoS5duqht27Z+7e3bt9e2bdv82rZt26Y2bdqUu2px+PBhvfrqq0pKSlJQUJA6dOggl8ul3Nxc9enTp8zjbNu2Tb169dIf//hHX9v//vUXGRmpvLw832uPx6NPPvnEt5itNCEhIb61IEBF/fOf/9TevXs1duxYXXPNNcrPz1etWrXKtVh427ZtGjZsmIYMGSLpx0rGwYMH/fr87+/6l19+qbNnz150zNDQUEnidx1VAslFDdepUyfdddddmjt3rl/7I488ouuvv16PP/64hg4dquzsbM2bN0/PPffcJcczTVP5+fkyTVMnT55Udna2pk+froiICN+9NerUqaNx48Zp7Nix8nq9+slPfqJTp05p27Ztqlu3rlJSUkodu3Xr1lq+fLnefvtttWjRQi+99JI++OADtWjRwtenX79+Sk1NVWZmpq699lrNnj37svv64+LilJWVpd69e8vlcql+/fpl+MkBktvtVn5+vjwejwoKCrRx40ZlZGTol7/8pZKTkxUUFKSEhAQlJSVp5syZatOmjb7//ntlZmZqyJAh6tGjR6njtm7dWmvXrtXAgQNlGIYmTZpU4t4Z/fr107x585SQkCCPx6Px48crJCTkorE2b95chmHozTff1IABAxQeHq7atWtb+vMAysxEjZKSkmIOHjzYry0nJ8cMDQ01//f/7tWrV5sdOnQwQ0JCzGbNmplPPfXUJcdesmSJKcmUZBqGYUZERJg33HCDOW3aNPPUqVN+fb1erzlnzhyzbdu2ZkhIiBkZGWn279/ffPfdd319IiIizCVLlvhe//DDD+awYcPMiIgIs169euaoUaPMCRMmmPHx8b4+xcXF5qhRo8wGDRqYUVFRZkZGhjl48GAzJSXF16d58+bmM88843u9fv16s1WrVmatWrXM5s2bX/IzAv+WkpLi+32vVauWGRkZaSYmJpqLFy82PR6Pr19hYaH54IMPmk2aNDFDQkLM2NhY86677jJzc3NN0zTN3bt3m5LMnJwc3zk5OTlm3759zfDwcDM2NtacN2+e2adPH3PMmDG+PocOHTJ/8YtfmFdffbXZunVrc8OGDX7fmZycHFOSuXv3bt8506ZNM2NiYkzDMPy+E0Bl45HrAADAUtznAgAAWIrkAgAAWIrkAgAAWIrkAgAAWIrkAgAAWIrkAgAAWIrkAgAAWIrkAqiBhg0bpqSkJN/rn/3sZ3r44YcrPY7NmzfLMIzL3kUVQM1CcgFUomHDhskwDBmGodDQULVq1UrTpk3ThQsXbL3u2rVr9fjjj5epLwkBgIri2SJAJbvlllu0ZMkSud1ubdiwQQ888IBCQkKUlpbm16+4uNj3MKqKatCggSXjAEBZULkAKpnL5VJMTIyaN2+uUaNGKTExUevXr/dNZTzxxBNq0qSJ70m23377re644w7Vq1dPDRo00ODBg/2eoOnxeJSamqp69eqpYcOGevTRR0s8qvt/p0XcbrfGjx+v2NhYuVwutWrVSi+++KIOHjzoe8Js/fr1ZRiGhg0bJknyer3KyMhQixYtFB4ervj4eK1evdrvOhs2bFCbNm0UHh6uvn37lnjSJ4DAQHIBOCw8PFzFxcWSpKysLO3fv1+bNm3Sm2++qfPnz6t///6qU6eO/vWvf2nbtm2qXbu2brnlFt85s2bN0tKlS7V48WJt3bpVx48f1+uvv37JayYnJ+u1117T3LlztW/fPv31r39V7dq1FRsbqzVr1kiS9u/fr7y8PP3lL3+RJGVkZGj58uVasGCBPv30U40dO1a///3v9e6770r6MQm6/fbbNXDgQO3Zs0f33nuvJkyYYNePDUBV5vCD04CA8t9PrfV6veamTZtMl8tljhs3zkxJSTGjo6NNt9vt6//SSy+Zbdu2Nb1er6/N7Xab4eHh5ttvv22apmk2btzYnDlzpu/98+fPm9dcc43f03H/+4mb+/fvNyWZmzZtKjXGd955x5Rknjhxwtf2ww8/mFdddZW5fft2v7733HOPeeedd5qmaZppaWlmhw4d/N4fP358ibEA1HysuQAq2ZtvvqnatWvr/Pnz8nq9+t3vfqcpU6bogQceUKdOnfzWWXz00Uf66quvVKdOHb8xfvjhBx04cECnTp1SXl6eevbs6XuvVq1a6tGjR4mpkX/bs2ePgoOD1adPnzLH/NVXX+ns2bO6+eab/dqLi4vVtWtXSdK+ffv84pCkhISEMl8DQM1BcgFUsr59++r5559XaGiomjRpolq1/vM1vPrqq/36FhUVqXv37nrllVdKjBMZGXlF1w8PDy/3OUVFRZKkzMxMNW3a1O89l8t1RXEAqLlILoBKdvXVV6tVq1Zl6tutWzetXLlSUVFRqlu3bql9GjdurPfff1833XSTJOnChQvauXOnunXrVmr/Tp06yev16t1331ViYmKJ9/9dOfF4PL62Dh06yOVyKTc396IVj/bt22v9+vV+be+9997lPySAGocFnUAVdtddd6lRo0YaPHiw/vWvfyknJ0ebN2/WQw89pO+++06SNGbMGM2YMUPr1q3T559/rj/+8Y+XvEdFXFycUlJSNGLECK1bt8435qpVqyRJzZs3l2EYevPNN3XkyBEVFRWpTp06GjdunMaOHatly5bpwIED2rVrl5599lktW7ZMknT//ffryy+/1J/+9Cft379fr776qpYuXWr3jwhAFURyAVRhV111lbZs2aJmzZrp9ttvV/v27XXPPffohx9+8FUyHnnkEd19991KSUlRQkKC6tSpoyFDhlxy3Oeff16//vWv9cc//lHt2rXTyJEjdebMGUlS06ZNNXXqVE2YMEHR0dEaPXq0JOnxxx/XpEmTlJGRofbt2+uWW25RZmamWrRoIUlq1qyZ1qxZo3Xr1ik+Pl4LFizQ9OnTbfzpAKiqDPNiq74AAACuAJULAABgKZILAABgKZILAABgKZILAABgKZILAABgKZILAABgKZILAABgKZILAABgKZILAABgKZILAABgKZILAABgKZILAABgqf8PE0Z6PMt5h1oAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 10: You're working for a FinTech company trying to predict loan default using customer demographics and transaction behavior.**\n",
        "# **The dataset is imbalanced, contains missing values, and has both numeric and categorical features.**\n",
        "# **Describe your step-by-step data science pipeline using boosting techniques:**\n",
        "# **● Data preprocessing & handling missing/categorical values**\n",
        "# **● Choice between AdaBoost, XGBoost, or CatBoost**\n",
        "# **● Hyperparameter tuning strategy**\n",
        "# **● Evaluation metrics you'd choose and why ● How the business would benefit from your model**\n"
      ],
      "metadata": {
        "id": "xq7uuU9lIJs-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Answer10 :**\n",
        "# Data Science Pipeline for Predicting Loan Default Using Boosting\n",
        "● Data Preprocessing & Handling Missing/Categorical Values\n",
        "- Missing Values : Impute missing numeric values with median or mean; for categoricals, impute with mode or create a \"missing\" category.\n",
        "- Categorical Feature: Encode categoricals using technioques like one-hot encoding or label encoding. Boosting libraries like CatBoost handle categoricals natively.\n",
        "\n",
        "● Choice between AdaBoost, XGBoost, or CatBoost\n",
        "- CatBoost or XGBoost : Prefer CatBoost or XGBoost for handling mixed data types and imbalanced datasets. CatBoost handles categorical features well; XGBoost is highly effective with proper encoding.\n",
        "\n",
        "● Hyperparameter Tuning Strategy\n",
        "- Use grid search or random search with cross-validation to tune hyperparameters like learning_rate , max_depth , subsample , and handle class imbalance via scale_pos_weight.\n",
        "\n",
        "● Evaluation Metrics You'd Choose and Why\n",
        "- AUC-ROC : Measures overall performance.\n",
        "- Precision, Recall, F1-score : Important for imbalanced datasets to assess model performance on the minority class (loan defaults).\n",
        "\n",
        "● How the Business Would Benefit from Your Model\n",
        "- Reduced Risk : Accurate loan default prediction reduces lending risks and potential losses.\n",
        "- Better Decision-Making : The model enables smarter lending decisions by assessing risk based on customer demographics and transaction behavior.\n",
        "\n",
        "Summary\n",
        "Using boosting (CatBoost/XGBoost) for loan default prediction handles mixed data types and imbalance. Hyperparameter tuning and evaluation via AUC-ROC and F1-score ensure a robust model benefiting the FinTech company by reducing risk.\n"
      ],
      "metadata": {
        "id": "TCVZJk02Jygx"
      }
    }
  ]
}