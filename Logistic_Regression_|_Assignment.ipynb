{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMY3tyJdn2T44t8g9AFIz+X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Himani954/Data-types-and-structure/blob/main/Logistic_Regression_%7C_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 1: What is Logistic Regression, and how does it differ from Linear Regression?**"
      ],
      "metadata": {
        "id": "WUvQ5RMnkpE_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Answer1:**\n",
        "Logistic Regression is a type of regression analysis used for predicting the probability of a binary outcome (e.g., 0 or 1, yes or no) based on one or more predictor variables. It uses a logistic function, also known as the sigmoid function, to model the probability of the outcome.\n",
        "\n",
        "Key differences from Linear Regression:\n",
        "\n",
        "1. Outcome variable : Logistic Regression is used for binary outcomes, while Linear Regression is used for continuous outcomes.\n",
        "2. Model form : Logistic Regression uses a logistic function to model probabilities, while Linear Regression uses a linear equation to model the outcome variable.\n",
        "3. Interpretation : Logistic Regression coefficients represent the change in log-odds of the outcome, while Linear Regression coefficients represent the change in the outcome variable.\n",
        "\n",
        "Logistic Regression is commonly used in applications such as:\n",
        "\n",
        "- Predicting customer churn (yes/no)\n",
        "- Classifying spam emails (spam/not spam)\n",
        "- Diagnosing diseases (disease/no disease)\n",
        "\n",
        "In contrast, Linear Regression is used for predicting continuous outcomes, such as:\n",
        "\n",
        "- Predicting house prices\n",
        "- Forecasting stock prices\n",
        "- Estimating the relationship between variables\n",
        "\n",
        "When to use Logistic Regression: when the outcome variable is binary or dichotomous. When to use Linear Regression: when the outcome variable is continuous."
      ],
      "metadata": {
        "id": "KfDjUrdpk4P1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 2: Explain the role of the Sigmoid function in Logistic Regression.**"
      ],
      "metadata": {
        "id": "4rVh0IsZRPXz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ans2.**\n",
        "# The Role of the Sigmoid Function in Logistic Regression\n",
        "\n",
        "The sigmoid function, also known as the logistic function, plays a crucial role in logistic regression. Its primary function is to map any real number to a value between 0 and 1. This is essential for modeling binary outcomes, where the probability of an event occurring is the primary interest.\n",
        "\n",
        "Properties of the Sigmoid Function:\n",
        "\n",
        "1. S-shaped curve : The sigmoid function has an S-shaped curve, which allows it to map large ranges of input values to a narrow range of output values between 0 and 1.\n",
        "2. Bounded output : The output of the sigmoid function is always between 0 and 1, making it ideal for modeling probabilities.\n",
        "3. Monotonic increase : The sigmoid function increases monotonically, meaning that as the input value increases, the output value also increases.\n",
        "\n",
        "Role in Logistic Regression:\n",
        "\n",
        "1. Modeling probabilities : The sigmoid function enables logistic regression to model the probability of an event occurring given the input variables.\n",
        "2. Binary classification : The sigmoid function is used to predict the probability of a binary outcome (0 or 1, yes or no, etc.).\n",
        "3. Thresholding : The output of the sigmoid function can be thresholded to make predictions. For example, a threshold of 0.5 can be used to classify instances as positive or negative.\n",
        "\n",
        "Benefits:\n",
        "\n",
        "1. Interpretable outputs : The sigmoid function provides interpretable outputs, allowing us to understand the probability of an event occurring.\n",
        "2. Robust modeling : The sigmoid function helps logistic regression models to be robust to outliers and noisy data.\n",
        "\n",
        "In summary, the sigmoid function is a critical component of logistic regression, enabling the model to output probabilities and make predictions for binary classification problems. Its properties, such as the S-shaped curve and bounded output, make it an ideal choice for modeling binary outcomes.\n",
        "\n"
      ],
      "metadata": {
        "id": "DYhvlu0rRhAv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 3: What is Regularization in Logistic Regression and why is it needed?**"
      ],
      "metadata": {
        "id": "b6PREdwSSun9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ans3.**\n",
        "# Regularization in Logistic Regression\n",
        "\n",
        "Regularization is a technique used in logistic regression to prevent overfitting by adding a penalty term to the loss function. This penalty term discourages large weights, which can lead to overfitting.\n",
        "\n",
        "Why is Regularization Needed?\n",
        "\n",
        "1. Prevents overfitting : Regularization helps to reduce overfitting by penalizing large weights, which can cause the model to fit the training data too closely.\n",
        "2. Reduces model complexity : Regularization simplifies the model by reducing the magnitude of the weights, making it less prone to capturing noise in the training data.\n",
        "3. Improves model generalization : Regularization helps the model to generalize better to new, unseen data.\n",
        "\n",
        "Types of Regularization:\n",
        "\n",
        "1. L1 Regularization (Lasso) : adds a term proportional to the absolute value of the weights.\n",
        "2. L2 Regularization (Ridge) : adds a term proportional to the square of the weights.\n",
        "\n",
        "Benefits:\n",
        "\n",
        "1. Improved model performance: Regularization can improve the model's performance on unseen data.\n",
        "2. Reduced risk of overfitting: Regularization reduces the risk of overfitting, making the model more robust.\n",
        "\n",
        "In logistic regression, regularization is essential to prevent overfitting and ensure that the model generalizes well to new data. By adding a penalty term to the loss function, regularization helps to simplify the model and improve its performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "_uqD8s4xS2dO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 4: What are some common evaluation metrics for classification models, and why are they important?**"
      ],
      "metadata": {
        "id": "AjP-hz_iTxX3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ans4.**\n",
        "# Common Evaluation Metrics for Classification Models\n",
        "\n",
        "1. Accuracy : Proportion of correctly classified instances out of total instances.\n",
        "2. Precision : Proportion of true positives among all positive predictions.\n",
        "3. Recall : Proportion of true positives among all actual positive instances.\n",
        "4. F1-score : Harmonic mean of precision and recall.\n",
        "5. AUC-ROC (Area Under the Receiver Operating Characteristic Curve): Measures model's ability to distinguish between classes.\n",
        "\n",
        "Why are they Important?\n",
        "\n",
        "1. Assessing model performance : These metrics provide insights into a model's strengths and weaknesses.\n",
        "2. Comparing models : Evaluation metrics enable comparison of different models and selection of the best-performing one.\n",
        "3. Identifying biases : Metrics like precision and recall help identify biases in the model, such as false positives or false negatives.\n",
        "4. Optimizing hyperparameters : Evaluation metrics guide Common Evaluation Metrics for Classification Models\n",
        "\n",
        "1. Accuracy : Proportion of correctly classified instances out of total instances.\n",
        "2. Precision : Proportion of true positives among all positive predictions.\n",
        "3. Recall : Proportion of true positives among all actual positive instances.\n",
        "4. F1-score : Harmonic mean of precision and recall.\n",
        "5. AUC-ROC (Area Under the Receiver Operating Characteristic Curve): Measures model's ability to distinguish between classes.\n",
        "\n",
        "Why are they Important?\n",
        "\n",
        "1. Assessing model performance : These metrics provide insights into a model's strengths and weaknesses.\n",
        "2. Comparing models : Evaluation metrics enable comparison of different models and selection of the best-performing one.\n",
        "3. Identifying biases : Metrics like precision and recall help identify biases in the model, such as false positives or false negatives.\n",
        "4. Optimizing hyperparameters : Evaluation metrics guide hyperparameter tuning to improve model performance.\n",
        "5. Business decision-making : These metrics inform business decisions, such as resource allocation and strategy development.\n",
        "\n",
        "Choosing the Right Metric:\n",
        "\n",
        "1. Class imbalance : Use metrics like F1-score or AUC-ROC when dealing with imbalanced classes.\n",
        "2. Cost-sensitive learning : Use metrics like precision and recall when costs are associated with false positives or false negatives.\n",
        "\n",
        "By using these evaluation metrics, you can develop and refine effective classification models that meet your specific needs and drive business success. tuning to improve model performance.\n",
        "5. Business decision-making : These metrics inform business decisions, such as resource allocation and strategy development.\n",
        "\n",
        "Choosing the Right Metric:\n",
        "\n",
        "1. Class imbalance : Use metrics like F1-score or AUC-ROC when dealing with imbalanced classes.\n",
        "2. Cost-sensitive learning : Use metrics like precision and recall when costs are associated with false positives or false negatives.\n",
        "\n",
        "By using these evaluation metrics, you can develop and refine effective classification models that meet your specific needs and drive business success.\n"
      ],
      "metadata": {
        "id": "lO31oFCST7p7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 5: Write a Python program that loads a CSV file into a Pandas DataFrame,splits into train/test sets, trains a Logistic Regression model, and prints its accuracy.**"
      ],
      "metadata": {
        "id": "RSi1-o0yVdKv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJkGCOQj0Fyj",
        "outputId": "8101ae44-037b-4f15-a9bc-98213557c71e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load CSV into DataFrame\n",
        "# Replace 'your_file.csv' with the actual file name\n",
        "df = pd.read_csv(\"height-weight.csv\")\n",
        "\n",
        "# Step 2: Separate features and target\n",
        "# Assuming the last column is the target\n",
        "X = df.iloc[:, :-1]  # all columns except last\n",
        "y = df.iloc[:, -1]   # last column as target\n",
        "\n",
        "# Step 3: Split into train and test sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Predict and calculate accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Step 6: Print accuracy\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 6: Write a Python program to train a Logistic Regression model using L2 regularization (Ridge) and print the model coefficients and accuracy.**"
      ],
      "metadata": {
        "id": "fkuqDWN0D7ge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load your dataset (replace with your actual CSV file)\n",
        "# For demonstration, using sklearn's built-in dataset\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Convert to DataFrame for easier handling\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "# Split data into features and target\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create Logistic Regression model with L2 regularization (default is L2)\n",
        "model = LogisticRegression(penalty='l2', solver='liblinear')  # or solver='lbfgs' for larger datasets\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print model coefficients\n",
        "print(\"Model Coefficients:\")\n",
        "print(model.coef_)\n",
        "\n",
        "# Print model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Model Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsPj0Of3Htx0",
        "outputId": "450fe870-4dab-48e6-ac1e-f264dfcd3700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Coefficients:\n",
            "[[ 2.13248406e+00  1.52771940e-01 -1.45091255e-01 -8.28669349e-04\n",
            "  -1.42636015e-01 -4.15568847e-01 -6.51940282e-01 -3.44456106e-01\n",
            "  -2.07613380e-01 -2.97739324e-02 -5.00338038e-02  1.44298427e+00\n",
            "  -3.03857384e-01 -7.25692126e-02 -1.61591524e-02 -1.90655332e-03\n",
            "  -4.48855442e-02 -3.77188737e-02 -4.17516190e-02  5.61347410e-03\n",
            "   1.23214996e+00 -4.04581097e-01 -3.62091502e-02 -2.70867580e-02\n",
            "  -2.62630530e-01 -1.20898539e+00 -1.61796947e+00 -6.15250835e-01\n",
            "  -7.42763610e-01 -1.16960181e-01]]\n",
            "Model Accuracy: 0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 7: Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr' and print the classification report.**"
      ],
      "metadata": {
        "id": "VHatISV3EMzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load a multiclass dataset (Iris dataset)\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model with One-vs-Rest strategy\n",
        "model = LogisticRegression(multi_class='ovr', solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=data.target_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK816EUdKH8Q",
        "outputId": "60d09b70-46d1-4456-a1b8-047336f188ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      1.00      1.00         9\n",
            "   virginica       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 8: Write a Python program to apply GridSearchCV to tune C and penalty hyperparameters for Logistic Regression and print the best parameters and validation accuracy.**"
      ],
      "metadata": {
        "id": "CNGH4TL1EYAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load sample dataset (Iris)\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "# Create Logistic Regression model\n",
        "model = LogisticRegression(solver='liblinear', multi_class='ovr')\n",
        "\n",
        "# Apply GridSearchCV\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and score\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Evaluate on test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Validation Accuracy on Test Set:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QveZGaYRNHqH",
        "outputId": "c417d92e-a248-4710-c8d3-d31c1536173f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 10, 'penalty': 'l1'}\n",
            "Validation Accuracy on Test Set: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 9: Write a Python program to standardize the features before training Logistic Regression and compare the model's accuracy with and without scaling.**"
      ],
      "metadata": {
        "id": "Qg8BvkrOErBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ---- Model without scaling ----\n",
        "model_no_scaling = LogisticRegression(max_iter=1000)\n",
        "model_no_scaling.fit(X_train, y_train)\n",
        "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "print(\"Accuracy without scaling:\", accuracy_no_scaling)\n",
        "\n",
        "# ---- Model with scaling ----\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_with_scaling = LogisticRegression(max_iter=1000)\n",
        "model_with_scaling.fit(X_train_scaled, y_train)\n",
        "y_pred_with_scaling = model_with_scaling.predict(X_test_scaled)\n",
        "accuracy_with_scaling = accuracy_score(y_test, y_pred_with_scaling)\n",
        "print(\"Accuracy with scaling:\", accuracy_with_scaling)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCkQQFcoN8HF",
        "outputId": "37849875-8a0b-421a-c5a4-bc6bd35a363b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 0.956140350877193\n",
            "Accuracy with scaling: 0.9736842105263158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 10: Imagine you are working at an e-commerce company that wants to predict which customers will respond to a marketing campaign. Given an imbalanced dataset (only 5% of customers respond), describe the approach you’d take to build a Logistic Regression model — including data handling, feature scaling, balancing classes, hyperparameter tuning, and evaluating the model for this real-world business use case.**"
      ],
      "metadata": {
        "id": "kHMS99mfEzH_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ans10.**\n",
        "\n",
        "# Approach to build a Logistic Regression model:\n",
        "\n",
        "1. Data Handling :\n",
        "    - Explore and clean the data (handle missing values, outliers, and data types).\n",
        "    - Split data into training (80%) and testing sets (20%).\n",
        "2. Feature Scaling :\n",
        "    - Use Standard Scaler or Min-Max Scaler to scale numerical features, ensuring all features are on the same scale.\n",
        "3. Balancing Classes :\n",
        "    - Use techniques like:\n",
        "        - Oversampling the minority class (responders)\n",
        "        - Undersampling the majority class (non-responders)\n",
        "        - SMOTE (Synthetic Minority Over-sampling Technique)\n",
        "        - Class weights (assign higher weights to the minority class)\n",
        "4. Hyperparameter Tuning :\n",
        "    - Use Grid Search or Random Search to tune hyperparameters like:\n",
        "        - Regularization strength (C)\n",
        "        - Penalty type (L1 or L2)\n",
        "    - Use cross-validation to evaluate model performance during tuning.\n",
        "5. Model Evaluation :\n",
        "    - Use metrics like:\n",
        "        - Precision\n",
        "        - Recall\n",
        "        - F1-score\n",
        "        - AUC-ROC\n",
        "    - Evaluate the model on the testing set to estimate its performance on unseen data.\n",
        "6. Model Interpretation :\n",
        "    - Analyze feature coefficients to understand the impact of each feature on the prediction.\n",
        "    - Use the model to identify the most important features driving customer responses.\n",
        "\n",
        "Business Use Case Considerations :\n",
        "\n",
        "1. Cost-sensitive learning : Consider the costs associated with false positives (targeting non-responders) and false negatives (missing responders).\n",
        "2. Model deployment : Deploy the model in a production-ready environment, integrating it with the marketing campaign system.\n",
        "3. Model monitoring : Continuously monitor the model's performance and retrain it as needed to maintain its effectiveness.\n",
        "\n",
        "By following this approach, you can develop a robust Logistic Regression model that effectively predicts customer responses to marketing campaigns, helping the e-commerce company optimize its marketing efforts.\n"
      ],
      "metadata": {
        "id": "odtVrGAmFXDn"
      }
    }
  ]
}